@article{Hoiem2005,
abstract = {This paper presents a fully automatic method for creating a 3D model from a single photograph. The model is made up of several texture-mapped planar billboards and has the complexity of a typical children's pop-up book illustration. Our main insight is that instead of attempting to recover precise geometry, we statistically model geometric classes defined by their orientations in the scene. Our algorithm labels regions of the input image into coarse categories: "ground", "sky", and "vertical". These labels are then used to "cut and fold" the image into a pop-up model using a set of simple assumptions. Because of the inherent ambiguity of the problem and the statistical nature of the approach, the algorithm is not expected to work on every image. However. it performs surprisingly well for a wide range of scenes taken from a typical person's photo album.},
author = {Hoiem, Derek and Efros, Alexei A and Hebert, Martial},
doi = {10.1145/1073204.1073232},
issn = {07300301},
journal = {ACM Transactions on Graphics},
keywords = {a large number,a result,all three,has largely been,image based rendering,image segmentation,left,machine learning,man,photographs,requiring special equipment,single view reconstruction,ual interaction},
number = {3},
pages = {577},
pmid = {19086030},
publisher = {ACM},
title = {{Automatic photo pop-up}},
url = {http://portal.acm.org/citation.cfm?doid=1073204.1073232},
volume = {24},
year = {2005}
}
@article{Liebowitz1999,
author = {Liebowitz, David and Criminisi, Antonio and Zisserman, Andrew},
doi = {10.1111/1467-8659.00326},
issn = {0167-7055},
journal = {Computer Graphics Forum},
month = sep,
number = {3},
pages = {39--50},
title = {{Creating Architectural Models from Images}},
url = {http://doi.wiley.com/10.1111/1467-8659.00326},
volume = {18},
year = {1999}
}
@article{Joachims2009,
abstract = {Abstract Discriminative training approaches like structural SVMs have shown much promise for building highly complex and accurate models in areas like natural language processing, protein structure prediction, and information retrieval. However, current training algorithms are computationally expensive or intractable on large datasets. To overcome this bottleneck, this paper explores how cutting-plane methods can provide fast training not only for classification SVMs, but also for structural SVMs. We show that for an equivalent 1-slack reformulation of the linear SVM training problem, our cutting-plane method has time complexity linear in the number of training examples. In particular, the number of iterations does not depend on the number of training examples, and it is linear in the desired precision and the regularization parameter. Furthermore, we present an extensive empirical evaluation of the method applied to binary classification, multi-class classification, HMM sequence tagging, and CFG parsing. The experiments show that the cutting-plane algorithm is broadly applicable and fast in practice. On large datasets, it is typically several orders of magnitude faster than conventional training methods derived from decomposition methods like SVM-light, or conventional cutting-plane methods. Implementations of our methods are available at www.joachims.org.},
author = {Joachims, Thorsten and Finley, Thomas and Yu, Chun-Nam John},
doi = {10.1007/s10994-009-5108-8},
issn = {08856125},
journal = {Machine Learning},
keywords = {structural svms,structured output predic,support vector machines,tion,training algorithms},
number = {1},
pages = {27--59},
publisher = {Springer},
title = {{Cutting-plane training of structural SVMs}},
url = {http://www.springerlink.com/index/10.1007/s10994-009-5108-8},
volume = {77},
year = {2009}
}
@article{Furukawa2009,
author = {Furukawa, Y and Curless, B},
journal = {Computer Vision, 2009  \ldots},
title = {{Reconstructing building interiors from images}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5459145},
year = {2009}
}
@article{Furukawa2009a,
author = {Furukawa, Y and Curless, B},
file = {:home/alex/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Furukawa, Curless - 2009 - Manhattan-world stereo.pdf:pdf},
journal = {Computer Vision and  \ldots},
title = {{Manhattan-world stereo}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5206867},
year = {2009}
}
@article{Scharstein2002,
abstract = {Stereo matching is one of the most active research areas in computer vision. While a large number of algorithms for stereo correspondence have been developed, relatively little work has been done on characterizing their performance. In this paper, we present a taxonomy of dense, two-frame stereo methods designed to assess the different components and design decisions made in individual stereo algorithms. Using this taxonomy, we compare existing stereo methods and present experiments evaluating the performance of many different variants. In order to establish a common software platform and a collection of data sets for easy evaluation, we have designed a stand-alone, flexible C++ implementation that enables the evaluation of individual components and that can be easily extended to include new algorithms. We have also produced several new multiframe stereo data sets with ground truth, and are making both the code and data sets available on the Web},
author = {Scharstein, D and Szeliski, R and Zabih, R},
doi = {10.1109/SMBV.2001.988771},
institution = {Microsoft Research},
isbn = {0769513271},
issn = {09205691},
journal = {Proceedings IEEE Workshop on Stereo and MultiBaseline Vision SMBV 2001},
number = {1},
pages = {131--140},
publisher = {IEEE Comput. Soc},
series = {Proceedings IEEE Workshop on Stereo and Multi-Baseline Vision (SMBV 2001)},
title = {{A taxonomy and evaluation of dense two-frame stereo correspondence algorithms}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=988771},
volume = {47},
year = {2002}
}
@article{Baillard1999,
author = {Baillard, C. and Baillard, C and Schmid, C and Zisserman, A and Fitzgibbon, A and England, Oxford Oxpj},
file = {:home/alex/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Baillard et al. - 1999 - Automatic Line Matching And 3D Reconstruction Of Buildings From Multiple Views.pdf:pdf},
journal = {ISPRS},
pages = {69 -- 80},
title = {{Automatic Line Matching And 3D Reconstruction Of Buildings From Multiple Views}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.30.9651},
volume = {32},
year = {1999}
}
@article{Longuet-Higgins1981,
abstract = {A simple computer algorithm for reconstructing the three-dimensional structure of a scene from a correlated pair of perspective projections when the spatial relationship between the two projections is unknown is presented. For the case in which the scene contains as many as eight points identifiable in both projections, it is shown that the relative orientation of the two projections can be computed from the eight sets of image coordinates by the solution of eight independent simultaneous linear equations. The spatial coordinates of all the visible points can then be obtained from a calculation of the translational vector and rigid rotation matrix expressing the relation between the two projections. The algorithm has a performance compatible with the human visual system, and may be important in computer vision systems.},
author = {Longuet-Higgins, H C},
doi = {10.1038/293133a0},
isbn = {8880551515},
issn = {00280836},
journal = {Nature},
number = {5828},
pages = {133--135},
publisher = {Morgan Kaufmann},
title = {{A computer algorithm for reconstructing a scene from two projections}},
url = {http://www.nature.com/doifinder/10.1038/293133a0},
volume = {293},
year = {1981}
}
@article{Marr1976,
abstract = {The extraction of stereo-disparity information from two images depends upon establishing a correspondence between them. In this article we analyze the nature of the correspondence computation and derive a cooperative algorithm that implements it. We show that this algorithm successfully extracts information from random-dot stereograms, and its implications for the psychophysics and neurophysiology of the visual system are briefly discussed.},
author = {Marr, D and Poggio, T},
journal = {Science},
number = {4262},
pages = {283--287},
pmid = {968482},
publisher = {Blackwell Pub},
title = {{Cooperative computation of stereo disparity.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/968482},
volume = {194},
year = {1976}
}
@article{Yang2010,
abstract = {Partitioning visual scenes into regions corresponding to the semantic-level object classes that they contain is an important problem in visual recognition. Recently, significant progress has been made by combining local appearance cues with contextual information via random field models. We present a fast, precise and highly scalable semantic segmentation algorithm that incorporates several kinds of local appearance features, example-based spatial layout priors, and neighborhood-level and global contextual information. The method works at the level of image patches. In the first stage, codebook based local appearance features are regularized and reduced in dimension using latent topic models, combined with spatial pyramid matching based spatial layout features, and fed into logistic regression classifiers to produce an initial patch level labeling. In the second stage, these labels are combined with patch-neighborhood and global aggregate features using either a second layer of Logistic Regression or a Conditional Random Field. Finally, the patch-level results are refined to pixel-level using MRF or over-segmentation based methods. The CRF is trained using a fast Maximum Margin approach. Comparative experiments on four multi-class segmentation datasets show that each of the above elements improves the results, leading to a scalable algorithm that is both faster and more accurate than existing patch-level approaches.},
author = {Yang, Wen and Triggs, William and Dai, Dengxin and Xia, Gui-Song},
file = {:home/alex/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang et al. - 2010 - Scene Segmentation with Low-dimensional Semantic Representations and Conditional Random Fields.pdf:pdf},
journal = {EURASIP Journal on Advances in Signal Processing},
keywords = {learning,machine vision,multimodal integration,statistics \& optimisation},
pages = {1--14},
publisher = {Hindawi Publishing Corporation},
title = {{Scene Segmentation with Low-dimensional Semantic Representations and Conditional Random Fields}},
url = {http://eprints.pascal-network.org/archive/00007173/},
volume = {2010},
year = {2010}
}
@article{blaschko2008learning,
author = {Blaschko, M. and Lampert, C.},
journal = {ECCV},
pages = {2--15},
publisher = {Springer},
title = {{Learning to localize objects with structured output regression}},
url = {http://www.springerlink.com/index/A2WU03T4M582G611.pdf},
year = {2008}
}
@inproceedings{li2008learning,
author = {Li, Y. and Huttenlocher, D.P.},
booktitle = {Proc. ECCV},
file = {:home/alex/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li, Huttenlocher - 2008 - Learning for stereo vision using the structured support vector machine.pdf:pdf},
pages = {1--8},
publisher = {IEEE},
title = {{Learning for stereo vision using the structured support vector machine}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4587699},
year = {2008}
}
@inproceedings{taskar2004max,
author = {Taskar, B. and Klein, D. and Collins, M. and Koller, D. and Manning, C.},
booktitle = {Proc. EMNLP},
file = {:home/alex/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Taskar et al. - 2004 - Max-margin parsing.pdf:pdf},
pages = {1--8},
title = {{Max-margin parsing}},
url = {http://acl.ldc.upenn.edu/acl2004/emnlp/pdf/Taskar.pdf},
year = {2004}
}
